{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime\n",
    "import time\n",
    "import requests\n",
    "import io\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from math import sqrt\n",
    "import  pylab as pl\n",
    "import numpy as np\n",
    "from datetime import timedelta\n",
    "from datetime import datetime\n",
    "from dateutil.relativedelta import relativedelta\n",
    "from pypfopt import EfficientFrontier\n",
    "from pypfopt import risk_models\n",
    "from pypfopt import expected_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_returns(x):\n",
    "    # save returns for each cluster in dictionary\n",
    "    # takes as input a dataframe containing the assets and corresponding cluster index\n",
    "    # returns a dictionary containing the returns for each cluster\n",
    "    ret_dict = {}\n",
    "    for i in unique: \n",
    "        lgc = x[\"Cluster\"] == i\n",
    "        ret_dict[i] = ret_test.loc[:,lgc.values]\n",
    "    \n",
    "    return(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_weights(x):\n",
    "    # compute equally weighted portfolio returns for each cluster\n",
    "    # takes a dictionary containing the cluster returns as input (output of cluster_returns)\n",
    "    # returns a dataframe containing the equally weighted portfolio returns\n",
    "    ret_ew = pd.DataFrame()\n",
    "\n",
    "    for i in x.keys(): \n",
    "        ret_ew = ret_ew.append(x[i].mean(axis = 1), ignore_index = True)\n",
    "\n",
    "    ret_ew = ret_ew.T\n",
    "    \n",
    "    return(ret_ew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rolling_portfolio(x):\n",
    "    # computes optimal portfolio weights on 252 days rolling windows (daily portfolio rebalancing)\n",
    "    # takes dataframe of cluster returns as input (output of equal_weights)\n",
    "    # returns dataframe of optimal portfolio weights for each cluster\n",
    "    window = 252\n",
    "\n",
    "    pesi_df = pd.DataFrame()\n",
    "\n",
    "    dates_dict = {}\n",
    "\n",
    "    for i in range( len(x) - window - 1 ):\n",
    "\n",
    "        # expected returns and sample covariance \n",
    "        rets_rolling = x.iloc[i:(i+window),:] \n",
    "        cluster_price = expected_returns.prices_from_returns(rets_rolling)\n",
    "        mu = expected_returns.mean_historical_return(cluster_price)\n",
    "        S = risk_models.sample_cov(cluster_price)\n",
    "\n",
    "        # maximum sharpe ratio (tangency) portfolio weights \n",
    "        ef = EfficientFrontier(mu, S)\n",
    "        raw_weights = ef.max_sharpe()\n",
    "        kmeans_weights = ef.clean_weights()\n",
    "        pesi_df = pesi_df.append( pd.DataFrame(kmeans_weights.values()).T )\n",
    "        dates_dict[i] = rets_rolling.index[-1] \n",
    "\n",
    "    pesi_df.index = pd.Index(dates_dict.values())\n",
    "    \n",
    "    return(pesi_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def static_portfolio(x):\n",
    "    # performs static portfolio optimization\n",
    "    # takes dataframe of cluster returns as input (output of equal_weights)\n",
    "    # returns dictionary of optimal portfolio weights for each cluster\n",
    "\n",
    "    cluster_price = expected_returns.prices_from_returns(x)\n",
    "    mu = expected_returns.mean_historical_return(cluster_price)\n",
    "    S = risk_models.sample_cov(cluster_price)\n",
    "\n",
    "    ef = EfficientFrontier(mu, S)\n",
    "    raw_weights = ef.max_sharpe()\n",
    "    weights = ef.clean_weights()\n",
    "    \n",
    "    return(weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download data\n",
    "Historical returns from about 200 stocks from Nasdaq, chosen randomly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime(2010,1,1)\n",
    "end = datetime(2020,12,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download symbols of all nasdaq components\n",
    "url=\"https://pkgstore.datahub.io/core/nasdaq-listings/nasdaq-listed_csv/data/7665719fb51081ba0bd834fde71ce822/nasdaq-listed_csv.csv\"\n",
    "s = requests.get(url).content\n",
    "companies = pd.read_csv(io.StringIO(s.decode('utf-8')))\n",
    "symbols = companies['Symbol'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# randomly select 500 assets\n",
    "random.seed(123)\n",
    "Symbols = random.sample(symbols, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download stock prices\n",
    "stock_final = pd.DataFrame()\n",
    "\n",
    "for i in Symbols:  \n",
    "    try:\n",
    "        stock = []\n",
    "        stock = yf.download(i,start=start, end=end, progress=False)\n",
    "        \n",
    "        if len(stock) == 0:\n",
    "            None\n",
    "        else:\n",
    "            stock['Name']= i\n",
    "            stock_final = stock_final.append(stock,sort=False)\n",
    "    except Exception:\n",
    "        None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of closing prices \n",
    "close = stock_final[[\"Close\", \"Name\"]]\n",
    "close_wide = close.pivot_table(index=\"Date\", columns='Name', values='Close')\n",
    "stock_price = close_wide.dropna(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_stocks = len(stock_price.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stock returns\n",
    "returns = stock_price.pct_change().iloc[1:]\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import returns\n",
    "returns = pd.read_pickle('returns.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import 3 month tbill\n",
    "tbills = pd.read_pickle('DTB3.pkl')\n",
    "\n",
    "# annualized tbill \n",
    "annualized = []\n",
    "\n",
    "for i in tbills['DTB3']:\n",
    "    try:\n",
    "       annualized.append((1 + float(i))**(1/252) - 1)\n",
    "    except ValueError:\n",
    "       annualized.append(0.0)\n",
    "\n",
    "tbills['DTB3A'] = annualized\n",
    "\n",
    "tbills.index = pd.to_datetime(tbills.index)\n",
    "tbills.index.names = ['Date']\n",
    "merged = pd.merge(tbills, returns, on='Date')\n",
    "tbill_ann = pd.DataFrame( merged[\"DTB3A\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and test set \n",
    "cutoff = \"2019-12-31\"\n",
    "\n",
    "ret_train = returns[returns.index <= cutoff]\n",
    "\n",
    "ret_test = returns[returns.index > (datetime.strptime(cutoff, '%Y-%m-%d') -  relativedelta(years=1))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-Means\n",
    "\n",
    "The k-means algorithm divides a set of $N$ samples $X$ into $C$ disjoint clusters, each described by the mean $\\mu_i$ \n",
    "of the samples in the cluster (the centroid). The K-means algorithm aims to choose centroids that minimise the within-cluster sum-of-squares:\n",
    "$$\n",
    "\\sum_{i=0}^{n} \\underset{\\mu_i \\in C}{min} (| x_i - \\mu_i |)^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# annual mean returns and variances \n",
    "mean_ret = ret_train.mean() * 252\n",
    "var_ret = ret_train.std() * sqrt(252)\n",
    "rets_df = pd.concat([mean_ret, var_ret], axis = 1)\n",
    "rets_df.columns = [\"Returns\",\"Variance\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select optimal number of clusters by minimizing SSE\n",
    "X =  rets_df.values \n",
    "sse = []\n",
    "\n",
    "random.seed(123)\n",
    "for k in range(2,15):\n",
    "    \n",
    "    kmeans = KMeans(n_clusters = k)\n",
    "    kmeans.fit(X)\n",
    "    \n",
    "    sse.append(kmeans.inertia_) #SSE for each cluster\n",
    "    \n",
    "pl.plot(range(2,15), sse)\n",
    "pl.title(\"Elbow Curve\")\n",
    "pl.xlabel('nr clusters')\n",
    "pl.ylabel('SSE')\n",
    "pl.axvline(x=5, c = \"k\", linestyle='dashed')\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit k-means with 5 clusters\n",
    "X = rets_df.values \n",
    "n_clusters = 5\n",
    "kmeans = KMeans(n_clusters = n_clusters).fit(X)\n",
    "centroids = kmeans.cluster_centers_\n",
    "\n",
    "pl.scatter(X[:,0],X[:,1], c = kmeans.labels_, cmap = \"rainbow\")\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove outlier (rerun previous chunk afterwards)\n",
    "outlier = mean_ret.idxmax()\n",
    "\n",
    "rets_df.drop(outlier, inplace = True)\n",
    "returns.drop(outlier, 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of elements in each cluster\n",
    "cluster_idx = np.array(kmeans.labels_)\n",
    "(unique, counts) = np.unique(cluster_idx, return_counts=True)\n",
    "frequencies = np.asarray((unique, counts)).T\n",
    "print(frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get cluster number for each asset\n",
    "asset = pd.DataFrame(rets_df.index)\n",
    "cluster_list = pd.concat([asset, pd.DataFrame(cluster_idx)],axis = 1)\n",
    "cluster_list.columns = [\"Asset\",\"Cluster\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rolling portfolio optimization K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save return series for each cluster in dictionary\n",
    "ret_dict = cluster_returns(cluster_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute equally weighted portfolio returns for each cluster\n",
    "ret_ew = equal_weights(ret_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimal portfolio weights on 252 days rolling windows (daily portfolio rebalancing)\n",
    "pesi_rol = rolling_portfolio(ret_ew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make sure return dates match weight dates \n",
    "lgc = ret_ew.index.isin(pesi_rol.index)\n",
    "ret_subs = ret_ew.iloc[lgc, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portfolio returns\n",
    "weighted_rets = ret_subs*pesi_rol\n",
    "rets_rol = weighted_rets.sum(axis = 1)\n",
    "\n",
    "# cumulative returns\n",
    "kmeans_rol = 100*( (rets_rol + 1).cumprod() - 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,7))\n",
    "ax1 = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax1.plot(kmeans_rol)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel(\"%\")\n",
    "ax1.set_title(\"Portfolio Cumulative Returns\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Static portfolio optimization K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# static portfolio optimization\n",
    "pesi_static = static_portfolio(ret_ew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# portfolio returns\n",
    "weighted_rets = ret_ew*list(pesi_static.values())\n",
    "rets_static = weighted_rets.sum(axis = 1)\n",
    "\n",
    "# make sure dates match in rolling and static implementation\n",
    "lgc = rets_static.index.isin(rets_rol.index)\n",
    "ret_fin = rets_static.iloc[lgc]\n",
    "\n",
    "# cumulative returns\n",
    "kmeans_static = 100*( (ret_fin + 1).cumprod() - 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,7))\n",
    "ax1 = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax1.plot(kmeans_static)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel(\"%\")\n",
    "ax1.set_title(\"Portfolio Cumulative Returns\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # calculate portfolio weights for each asset\n",
    "# kmeans_w = pd.DataFrame()\n",
    "\n",
    "# names_assets = pd.Index([])\n",
    "\n",
    "# for i in pesi_static.keys():\n",
    "    \n",
    "#     w = pesi_static[i]\n",
    "#     pesi = [w*1/len(ret_dict[i].columns)]*len(ret_dict[i].columns)\n",
    "#     kmeans_w = kmeans_w.append( pd.DataFrame(pesi) )\n",
    "#     names_assets = names_assets.union( ret_dict[i].columns )\n",
    "\n",
    "# kmeans_w.index = names_assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# excess return from daily rebalancing\n",
    "extraret = kmeans_rol - kmeans_static\n",
    "\n",
    "fig = plt.figure(figsize=(15,7))\n",
    "ax1 = fig.add_axes([0.1,0.1,0.8,0.8])\n",
    "ax1.plot(extraret)\n",
    "ax1.set_xlabel('Date')\n",
    "ax1.set_ylabel(\"%\")\n",
    "ax1.set_title(\"Excess Return\")\n",
    "plt.show();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
